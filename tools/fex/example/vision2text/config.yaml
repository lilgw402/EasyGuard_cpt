
# 数据集相关的配置
DATASET:
  TRAIN_PATH: hdfs://haruna/home/byte_search_nlp_lq/user/huangwenguan/data/query/join_bk_dyj_ent_igm_s7r1kr01
  VAL_PATH: hdfs://haruna/home/byte_search_nlp_lq/user/huangwenguan/data/query/join_bk_dyj_ent_igm_s7r1kr01
  VOCAB_FILE: hdfs://haruna/home/byte_search_nlp_lq/user/huangwenguan/modelhub/albert_6l_zh_mix_oldcut_20200921/archer/zh_old_cut_145607.vocab

# 模型相关的配置
NETWORK:
  vocab_size: 145608
  n_embd: 256
  num_hidden_layers: 8
  hidden_size: 512
  seq_length: 16
  n_head: 8
  attn_pdrop: 0.1
  resid_pdrop: 0.1
  embd_pdrop: 0.1
  pretrained_model_path: 'hdfs://haruna/home/byte_search_nlp_lq/user/huangwenguan/vl/model/pretrained_model/resnet50-19c8e357-t3.pth'
  visual_type: RN50
  visual_hidden: 2048

# 训练的一些超参数
TRAIN:
  LR: 6.0e-4
  LR_SCHEDULE: linear
  MAX_PREFETCH: 4
  MOMENTUM: 0.9
  NUM_WORKERS: 8
  OPTIM: AdamW
  WARMUP_FACTOR: 0.001
  WD: 0.0001

# trianer 相关的配置
TRAINER:
  BEGIN_EPOCH: 0
  END_EPOCH: 16
  TRAIN_BATCH_SIZE: 512
  TRAIN_DATASET_SIZE: 10000000
  VAL_BATCH_SIZE: 16
  VAL_DATASET_SIZE: 50000
  VAL_FREQUENT: 6000
  VAL_STEPS: 10
  CHECKPOINT_FREQUENT: 2000
  LOG_FREQUENT: 100
  RNG_SEED: 42

# val 相关的配置
VAL:
  NUM_WORKERS: 4

# 训练加速相关的配置
ACCELERATOR:
  CLIP_GRAD_NORM: 1.0
  FP16: true
  FP16_LOSS_SCALE: dynamic
  FP16_OPT_LEVEL: O2
  GRAD_ACCUMULATE_STEPS: 1
  SYNCBN: false